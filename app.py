import streamlit as st
import numpy as np
import pandas as pd
import re
from collections import Counter
import jieba
import zlib

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="AI/Human Detector Tuned",
    page_icon="âš–ï¸",
    layout="wide"
)

# --- ç¯„ä¾‹è³‡æ–™åº« ---
EXAMPLES = {
    "English": [
        {
            "type": "AI",
            "text": "Artificial Intelligence involves the development of algorithms that allow computers to perform tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, and language understanding. Machine learning, a subset of AI, focuses on building systems that learn from data. As technology advances, AI is becoming increasingly integrated into various sectors, including healthcare, finance, and transportation."
        },
        {
            "type": "Human",
            "text": "I literally cannot believe what just happened to me at the coffee shop! So, I ordered my usual latte, right? And the barista, who looked totally asleep, handed me a cup that felt way too light. I took a sip andâ€”BAMâ€”it was just hot milk! No coffee at all. Seriously? I just stood there laughing because, honestly, it's been that kind of week. Who forgets the coffee in a latte?"
        },
        {
            "type": "AI",
            "text": "Regular physical exercise is crucial for maintaining good overall health. It offers numerous benefits for both the body and the mind. Engaging in consistent physical activity helps to control body weight effectively. Furthermore, exercise can improve cardiovascular health significantly over time. Additionally, it strengthens muscles and bones, reducing the risk of injury. Regular physical exercise also boosts mental health by reducing stress and anxiety levels. Therefore, incorporating physical activity into one's daily routine is highly recommended for a healthy lifestyle."
        },
        {
            "type": "Human",
            "text": "You know that feeling when you finish a really good book and you just stare at the wall for like ten minutes? That was me last night. The ending was so unexpected, yet it made perfect sense. I was crying, smiling, just a total mess. I wish I could erase my memory and read it all over again for the first time. Truly a masterpiece."
        }
    ],
    "Traditional Chinese (ç¹ä¸­)": [
        {
            "type": "AI",
            "text": "å€å¡ŠéˆæŠ€è¡“æ˜¯ä¸€ç¨®å»ä¸­å¿ƒåŒ–çš„åˆ†æ•£å¼å¸³æœ¬æŠ€è¡“ï¼Œå®ƒç¢ºä¿äº†è³‡æ–™çš„é€æ˜æ€§èˆ‡ä¸å¯ç¯¡æ”¹æ€§ã€‚æ¯ä¸€å€‹å€å¡Šéƒ½åŒ…å«äº†å‰ä¸€å€‹å€å¡Šçš„åŠ å¯†é›œæ¹Šå€¼ã€æ™‚é–“æˆ³è¨˜ä»¥åŠäº¤æ˜“è³‡æ–™ã€‚é€™ç¨®çµæ§‹ä½¿å¾—å€å¡Šéˆåœ¨é‡‘èç§‘æŠ€ã€ä¾›æ‡‰éˆç®¡ç†ä»¥åŠæ™ºæ…§åˆç´„ç­‰é ˜åŸŸå±•ç¾å‡ºå·¨å¤§çš„æ‡‰ç”¨æ½›åŠ›ã€‚éš¨è‘—æŠ€è¡“çš„æˆç†Ÿï¼Œæˆ‘å€‘é è¨ˆå°‡çœ‹åˆ°æ›´å¤šåŸºæ–¼å€å¡Šéˆçš„å‰µæ–°è§£æ±ºæ–¹æ¡ˆã€‚"
        },
        {
            "type": "Human",
            "text": "æ˜¨å¤©è·Ÿæœ‹å‹å»æ’é‚£å®¶æ–°é–‹çš„æ‹‰éºµåº—ï¼ŒçœŸçš„æ’åˆ°å¤©è’åœ°è€ï¼æˆ‘å€‘åœ¨å¯’é¢¨ä¸­ç«™äº†å¿«å…©å€‹å°æ™‚ï¼Œè…³éƒ½å¿«æ–·äº†ã€‚çµæœé€²å»ä¸€åƒï¼Œå“‡è³½ï¼Œé‚£å€‹æ¹¯é ­æ¿ƒéƒåˆ°ä¸è¡Œï¼Œå‰ç‡’ä¹Ÿæ˜¯å…¥å£å³åŒ–ï¼Œç¬é–“è¦ºå¾—å‰›å‰›çš„è¾›è‹¦éƒ½å€¼å¾—äº†ã€‚é›–ç„¶é€™å®¶åº—çš„åƒ¹æ ¼æœ‰é»å°è²´ï¼Œä½†ä¹…ä¹…åƒä¸€æ¬¡çŠ’è³è‡ªå·±æ‡‰è©²ä¸éåˆ†å§ï¼Ÿä¸‹æ¬¡ä¸€å®šè¦æŒ‘å¹³æ—¥ä¾†ï¼Œä¸ç„¶çœŸçš„æœƒç­‰åˆ°ç˜‹æ‰ã€‚"
        },
        {
            "type": "AI",
            "text": "ç’°å¢ƒä¿è­·æ˜¯ç•¶ä»Šå…¨çƒé¢è‡¨çš„ä¸€å€‹é‡è¦è­°é¡Œã€‚éš¨è‘—å·¥æ¥­åŒ–çš„å¿«é€Ÿç™¼å±•ï¼Œè‡ªç„¶çš„ç”Ÿæ…‹å¹³è¡¡å—åˆ°äº†åš´é‡çš„æŒ‘æˆ°ã€‚æˆ‘å€‘å¿…é ˆæ„è­˜åˆ°ä¿è­·åœ°çƒå®¶åœ’çš„ç·Šè¿«æ€§èˆ‡å¿…è¦æ€§ã€‚æ¸›å°‘ä¸€æ¬¡æ€§å¡‘è† è£½å“çš„ä½¿ç”¨æ˜¯ä¸€å€‹é—œéµçš„æ­¥é©Ÿã€‚æ­¤å¤–ï¼Œç©æ¥µæ¨å»£å†ç”Ÿèƒ½æºçš„æ‡‰ç”¨ä¹Ÿæ˜¯éå¸¸é‡è¦çš„æªæ–½ã€‚æ¯å€‹äººéƒ½æ‡‰è©²æé«˜è‡ªèº«çš„ç’°ä¿æ„è­˜ä¸¦æ¡å–å¯¦éš›è¡Œå‹•ã€‚åªæœ‰é€éå…±åŒçš„åŠªåŠ›ï¼Œæˆ‘å€‘æ‰èƒ½å¯¦ç¾å¯æŒçºŒç™¼å±•çš„é•·é ç›®æ¨™ã€‚"
        },
        {
            "type": "Human",
            "text": "æ•‘å‘½å•Šï¼æˆ‘åˆšåˆšæŠŠæ‰‹æ©Ÿå¿˜åœ¨è¨ˆç¨‹è»Šä¸Šäº†ï¼Œç¾åœ¨æ•´å€‹äººè¶…ç„¦æ…®ã€‚è£¡é¢æœ‰æˆ‘æ‰€æœ‰çš„ç…§ç‰‡é‚„æœ‰æ²’å‚™ä»½çš„è¯çµ¡äººè³‡æ–™ï¼Œå¦‚æœæ‰¾ä¸å›ä¾†æˆ‘çœŸçš„æœƒå´©æ½°ã€‚å¸æ©Ÿå¤§å“¥ä¹Ÿä¸æ¥é›»è©±ï¼Œå®¢æœåˆä¸€ç›´å¿™ç·šä¸­ï¼Œé€™åˆ°åº•æ˜¯ç”šéº¼å€’æ¥£çš„ä¸€å¤©ï¼Ÿæ‹œè¨—å¥½å¿ƒäººå¦‚æœæ’¿åˆ°å¯ä»¥é€å»è­¦å¯Ÿå±€ï¼Œæˆ‘é¡˜æ„è«‹ä½ åƒå¤§é¤ç­”è¬ï¼ŒçœŸçš„æ‹œè¨—äº†ï¼"
        }
    ]
}

# --- Session State åˆå§‹åŒ– ---
if 'input_text' not in st.session_state: st.session_state['input_text'] = ""
if 'example_index' not in st.session_state: st.session_state['example_index'] = 0

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    lang_mode = st.radio("é¸æ“‡èªè¨€æ¨¡å¼", ["Traditional Chinese (ç¹ä¸­)", "English"])
    st.info("âš ï¸ å·²å•Ÿç”¨ã€Œé«˜éˆæ•åº¦æ¨¡å¼ã€ä»¥åŠ å¼· AI åµæ¸¬èƒ½åŠ›ã€‚")

st.title(f"âš–ï¸ {lang_mode.split('(')[0]} æ–‡æœ¬åµæ¸¬å™¨ (Tuned)")

STOPWORDS_EN = set(['the', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'of', 'in', 'on', 'at', 'to', 'it', 'this', 'that'])
STOPWORDS_ZH = set(['çš„', 'äº†', 'å’Œ', 'æ˜¯', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'èˆ‡', 'è‘—', 'æˆ–', 'ä¸€å€‹', 'æ²’æœ‰', 'æˆ‘å€‘', 'ä½ å€‘', 'ä»–å€‘', 'åœ¨', 'é€™', 'é‚£'])

# --- æ ¸å¿ƒé‚è¼¯ (åƒæ•¸å·²èª¿æ ¡) ---
def analyze_text_features(text, mode):
    clean_text = text.strip()
    if not clean_text: return None

    # 1. æ–·è©æ–·å¥
    sentences, words, stopwords = [], [], []
    if mode == "English":
        sentences = re.split(r'[.!?\n]+', clean_text)
        words = re.findall(r'\w+', clean_text.lower())
        stopwords = STOPWORDS_EN
    else:
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]+', clean_text)
        words = list(jieba.cut(clean_text))
        words = [w for w in words if w.strip() and len(w) > 0]
        stopwords = STOPWORDS_ZH

    sentences = [s.strip() for s in sentences if len(s.strip()) > 0]
    if len(words) < 5: return None

    # 2. è¨ˆç®—ç‰¹å¾µæ•¸å€¼
    if mode == "English":
        sentence_lengths = [len(s.split()) for s in sentences]
    else:
        sentence_lengths = [len(list(jieba.cut(s))) for s in sentences]
    
    avg_len = np.mean(sentence_lengths)
    std_dev = np.std(sentence_lengths) if len(sentence_lengths) > 1 else 0

    unique_words = set(words)
    ttr = len(unique_words) / len(words)
    
    text_bytes = clean_text.encode('utf-8')
    compressed_data = zlib.compress(text_bytes)
    compression_ratio = len(compressed_data) / len(text_bytes)

    # --- 3. è©•åˆ†é‚è¼¯ (Tuned Thresholds) ---
    score_std = 0.5
    score_ttr = 0.5
    score_zlib = 0.5

    # [èª¿æ•´é» 1] æ”¾å¯¬ Std Dev åˆ¤å®šï¼šè‹±æ–‡ 7 ä»¥ä¸‹éƒ½ç®—å¹³ç©©(AI)ï¼Œä¸­æ–‡ 5 ä»¥ä¸‹
    # ç†ç”±ï¼šç¾ä»£ AI æ¯”è¼ƒæœƒæ›å¥é•·äº†ï¼Œæ‰€ä»¥è¦æé«˜ AI çš„å®¹è¨±ç¯„åœ
    thresh_std_ai = 7.0 if mode == "English" else 5.0
    
    if std_dev < thresh_std_ai: 
        score_std = 1.0 # å¼·çƒˆæ‡·ç–‘æ˜¯ AI
    elif std_dev > (thresh_std_ai + 5): 
        score_std = 0.0 # Human
    else:
        # ä¸­é–“åœ°å¸¶ï¼Œç¨å¾®åå‘ Human
        score_std = 0.4

    # [èª¿æ•´é» 2] TTR èª¿æ•´
    if ttr < 0.45: score_ttr = 1.0
    elif ttr > 0.65: score_ttr = 0.0
    else: score_ttr = 0.4

    # [èª¿æ•´é» 3] Zlib å£“ç¸®ç‡èª¿æ•´ (æœ€é‡è¦)
    # çŸ­æ–‡æœ¬å£“ç¸®ç‡æœƒè™›é«˜ï¼Œæ‰€ä»¥è¦æ”¾å¯¬ AI çš„ä¸Šé™
    # è‹±æ–‡ï¼š0.45 ä»¥ä¸‹è¦–ç‚º AI (åŸæœ¬æ˜¯ 0.38)
    # ä¸­æ–‡ï¼š0.55 ä»¥ä¸‹è¦–ç‚º AI (åŸæœ¬æ˜¯ 0.43)
    thresh_zlib_ai = 0.45 if mode == "English" else 0.55
    
    if compression_ratio < thresh_zlib_ai: 
        score_zlib = 1.0
    elif compression_ratio > (thresh_zlib_ai + 0.1): 
        score_zlib = 0.0
    else:
        score_zlib = 0.4

    # åŠ æ¬Šå¹³å‡ (ç¨å¾®é™ä½ TTR æ¬Šé‡ï¼Œå› ç‚ºçŸ­æ–‡ TTR ä¸æº–)
    final_score = (score_std * 0.35) + (score_ttr * 0.25) + (score_zlib * 0.40)
    
    return {
        "score": final_score, 
        "features": {
            "std_dev": std_dev,
            "ttr": ttr,
            "compression_ratio": compression_ratio,
            "thresh_std_ai": thresh_std_ai,     # å›å‚³é–¾å€¼çµ¦ Debug çœ‹
            "thresh_zlib_ai": thresh_zlib_ai    # å›å‚³é–¾å€¼çµ¦ Debug çœ‹
        },
        "sentence_lengths": sentence_lengths,
        "avg_len": avg_len, 
        "word_counts": Counter([w for w in words if w not in stopwords and len(w)>1]),
        "total_sentences": len(sentences)
    }

# --- UI ---
col_input, col_result = st.columns([1, 2])

with col_input:
    st.subheader("ğŸ“ è¼¸å…¥å€")
    
    def load_next_example():
        key = "English" if "English" in lang_mode else "Traditional Chinese (ç¹ä¸­)"
        examples = EXAMPLES[key]
        idx = st.session_state['example_index'] % len(examples)
        selected = examples[idx]
        st.session_state['input_text'] = selected['text']
        st.toast(f"å·²è¼‰å…¥ç¯„ä¾‹ #{idx+1} ({selected['type']})", icon="âœ…")
        st.session_state['example_index'] += 1

    st.button("ğŸ² è¼‰å…¥ç¯„ä¾‹ (è¼ªæ’­)", on_click=load_next_example, type="secondary")

    user_input = st.text_area("Input Text", height=350, key="input_text", placeholder="è¼¸å…¥æ–‡å­—...", label_visibility="collapsed")
    analyze_btn = st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary")

if analyze_btn and user_input:
    data = analyze_text_features(user_input, lang_mode)
    
    if data is None:
        st.warning("âš ï¸ æ–‡æœ¬éçŸ­")
    else:
        with col_result:
            score = data['score']
            
            # è®“åˆ¤å®šç¨å¾®åš´æ ¼ä¸€é»ï¼š > 0.55 å°±ç®—ç–‘ä¼¼ AI
            if score > 0.55:
                res_txt, res_color = "ç–‘ä¼¼ AI ç”Ÿæˆ", "red"
            elif score < 0.35:
                res_txt, res_color = "ç–‘ä¼¼ Human æ’°å¯«", "green"
            else:
                res_txt, res_color = "æ··åˆç‰¹å¾µ / ä¸ç¢ºå®š", "orange"

            st.markdown(f"""
            <div style="padding:15px; border-radius:10px; background-color:rgba(128,128,128,0.1); border-left: 6px solid {res_color}">
                <h3 style="margin:0; color:{res_color}">{res_txt}</h3>
                <p style="margin:5px 0 0 0; opacity:0.8">AI å¯èƒ½æ€§æŒ‡æ•¸: <b>{int(score*100)}%</b></p>
            </div>
            """, unsafe_allow_html=True)
            
            # --- Debug å€å¡Šï¼šé€™æ˜¯ä½ æª¢æŸ¥ç‚ºä»€éº¼ã€Œå…¨éƒ¨éƒ½åˆ¤æˆ Humanã€çš„é—œéµ ---
            with st.expander("ğŸ é–‹ç™¼è€…æ•¸æ“š (Debug Info)", expanded=True):
                f = data['features']
                st.write("å¦‚æœæ•¸å€¼ **å°æ–¼** é–¾å€¼ï¼Œæœƒè¢«åˆ¤å®šç‚º AIã€‚")
                
                c_d1, c_d2, c_d3 = st.columns(3)
                c_d1.metric("å¥é•·æ³¢å‹• (Std)", f"{f['std_dev']:.2f}", f"é–¾å€¼: {f['thresh_std_ai']}")
                c_d2.metric("å£“ç¸®ç‡ (Zlib)", f"{f['compression_ratio']:.2f}", f"é–¾å€¼: {f['thresh_zlib_ai']}")
                c_d3.metric("è©å½™è±å¯Œåº¦", f"{f['ttr']:.2f}", "é–¾å€¼: 0.45")
                
                st.caption(f"ç›®å‰åˆ†æ•¸: {score:.2f} (0=Human, 1=AI)")

            # åœ–è¡¨
            tab1, tab2 = st.tabs(["ğŸ“ˆ å¥é•·æ³¢å‹•", "ğŸ”  è©å½™çµ±è¨ˆ"])
            with tab1:
                st.line_chart(pd.DataFrame({"Len": data['sentence_lengths']}), color="#FF4B4B")
            with tab2:
                top_words = data['word_counts'].most_common(10)
                if top_words: st.bar_chart(pd.DataFrame(top_words, columns=["W", "C"]).set_index("W"))