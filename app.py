import streamlit as st
from transformers import pipeline
import time

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="AI vs Human Detector",
    page_icon="ğŸ¤–",
    layout="centered"
)

st.title("ğŸ¤– AI æ–‡æœ¬åµæ¸¬å™¨ (AI Detector)")
st.write("é€™æ˜¯ä¸€å€‹åŸºæ–¼ Transformer æ¨¡å‹çš„ç°¡å–®æª¢æ¸¬å·¥å…·ï¼Œç”¨æ–¼åˆ¤æ–·æ–‡æœ¬æ˜¯ç”± **äººé¡** é‚„æ˜¯ **AI** æ’°å¯«çš„ã€‚")

# --- 1. è¼‰å…¥æ¨¡å‹ (ä½¿ç”¨ @st.cache_resource é¿å…é‡è¤‡è¼‰å…¥) ---
@st.cache_resource
def load_detector_model():
    # é€™è£¡ä½¿ç”¨ roberta-base-openai-detector (ç¶“å…¸æ¨¡å‹)
    # æ³¨æ„ï¼šé¦–æ¬¡åŸ·è¡Œæœƒä¸‹è¼‰æ¨¡å‹ (ç´„ 500MB)ï¼Œè«‹è€å¿ƒç­‰å¾…
    model_name = "roberta-base-openai-detector"
    classifier = pipeline("text-classification", model=model_name)
    return classifier

# é¡¯ç¤ºè¼‰å…¥ç‹€æ…‹
with st.spinner("æ­£åœ¨è¼‰å…¥ AI åµæ¸¬æ¨¡å‹..."):
    try:
        classifier = load_detector_model()
    except Exception as e:
        st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£æ¥æˆ–å¥—ä»¶å®‰è£: {e}")
        st.stop()

# --- 2. UI ä»‹é¢ ---
st.markdown("### ğŸ“ è«‹è¼¸å…¥è¦æª¢æ¸¬çš„æ–‡æœ¬")
user_input = st.text_area(
    "åœ¨é€™è£¡è²¼ä¸Šæ–‡ç« å…§å®¹ (å»ºè­°è¼¸å…¥ 50 å­—ä»¥ä¸Š)...",
    height=200,
    placeholder="Once upon a time, in a land far away..."
)

# --- 3. åµæ¸¬é‚è¼¯ ---
if st.button("é–‹å§‹åµæ¸¬ (Analyze)", type="primary"):
    if not user_input.strip():
        st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥å…§å®¹å†é€²è¡Œåµæ¸¬ï¼")
    else:
        # é¡¯ç¤ºè™•ç†ä¸­çš„ç‹€æ…‹
        progress_text = "æ­£åœ¨åˆ†ææ–‡æœ¬ç‰¹å¾µ..."
        my_bar = st.progress(0, text=progress_text)
        
        # æ¨¡æ“¬ä¸€é»é€²åº¦æ¢å‹•ç•« (è®“ UI æ„Ÿè¦ºæ›´é †æš¢)
        for percent_complete in range(100):
            time.sleep(0.005)
            my_bar.progress(percent_complete + 1, text=progress_text)
        
        # ä½¿ç”¨æ¨¡å‹é€²è¡Œé æ¸¬
        # æ¨¡å‹æœƒå›å‚³ [{'label': 'Fake', 'score': 0.99...}] æˆ– [{'label': 'Real', 'score': ...}]
        # åœ¨æ­¤æ¨¡å‹ä¸­ï¼Œ'Fake' = AI ç”Ÿæˆ, 'Real' = äººé¡æ’°å¯«
        result = classifier(user_input)[0]
        
        my_bar.empty() # æ¸…é™¤é€²åº¦æ¢

        # --- 4. çµæœè§£æèˆ‡è¦–è¦ºåŒ– ---
        label = result['label']
        score = result['score']
        
        # è½‰æ›é‚è¼¯ï¼šè¨ˆç®— AI çš„æ©Ÿç‡èˆ‡ Human çš„æ©Ÿç‡
        if label == 'Fake':
            ai_prob = score
            human_prob = 1 - score
        else:
            human_prob = score
            ai_prob = 1 - score
            
        # è½‰æ›æˆç™¾åˆ†æ¯”
        ai_percent = ai_prob * 100
        human_percent = human_prob * 100

        # --- é¡¯ç¤ºçµæœå€å¡Š ---
        st.markdown("---")
        st.subheader("ğŸ“Š æª¢æ¸¬çµæœ (Analysis Result)")

        col1, col2 = st.columns(2)

        with col1:
            st.metric(label="ğŸ¤– AI å¯èƒ½æ€§", value=f"{ai_percent:.1f}%")
            st.progress(ai_prob) # é¡¯ç¤º AI é€²åº¦æ¢

        with col2:
            st.metric(label="ğŸ§‘ Human å¯èƒ½æ€§", value=f"{human_percent:.1f}%")
            # Human é€²åº¦æ¢ (ç‚ºäº†è¦–è¦ºå€éš”ï¼Œä½ å¯ä»¥é¸æ“‡ä¸é¡¯ç¤ºæˆ–ç”¨ä¸åŒé¡è‰²ï¼ŒStreamlit é è¨­åŒè‰²)
            st.progress(human_prob)

        # æœ€çµ‚åˆ¤æ–·çµè«–
        st.markdown("### çµè«–ï¼š")
        if ai_prob > 0.5:
            st.error(f"é€™ç¯‡æ–‡ç«  **{ai_percent:.1f}%** åƒæ˜¯ç”± AI ç”Ÿæˆçš„ã€‚")
        else:
            st.success(f"é€™ç¯‡æ–‡ç«  **{human_percent:.1f}%** åƒæ˜¯ç”±äººé¡æ’°å¯«çš„ã€‚")

# --- å´é‚Šæ¬„è³‡è¨Š ---
with st.sidebar:
    st.info("â„¹ï¸ é—œæ–¼æ­¤å·¥å…·")
    st.markdown("""
    - **æ¨¡å‹ä¾†æº**: huggingface/roberta-base-openai-detector
    - **åŸç†**: ä½¿ç”¨é è¨“ç·´çš„ Transformer æ¶æ§‹åˆ†æèªæ„ç‰¹å¾µèˆ‡å›°æƒ‘åº¦ (Perplexity)ã€‚
    - **é™åˆ¶**: å°æ–¼æœ€æ–°çš„ GPT-4 æ¨¡å‹å¯èƒ½æº–ç¢ºåº¦æœƒä¸‹é™ã€‚
    """)