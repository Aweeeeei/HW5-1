import streamlit as st
import numpy as np
import pandas as pd
import re
from collections import Counter
import jieba
import zlib  # <--- æ–°å¢æ ¸å¿ƒï¼šç”¨æ–¼è¨ˆç®—è³‡è¨Šç†µ (å£“ç¸®ç‡)

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="AI/Human Detector Ultra",
    page_icon="ğŸ§¬",
    layout="wide"
)

# --- å®šç¾©ç¯„ä¾‹è³‡æ–™åº« (åŒ…å«ä¹‹å‰çš„æ“´å……ç¯„ä¾‹) ---
EXAMPLES = {
    "English": [
        {
            "type": "AI",
            "text": "Artificial Intelligence involves the development of algorithms that allow computers to perform tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, and language understanding. Machine learning, a subset of AI, focuses on building systems that learn from data. As technology advances, AI is becoming increasingly integrated into various sectors, including healthcare, finance, and transportation."
        },
        {
            "type": "Human",
            "text": "I literally cannot believe what just happened to me at the coffee shop! So, I ordered my usual latte, right? And the barista, who looked totally asleep, handed me a cup that felt way too light. I took a sip andâ€”BAMâ€”it was just hot milk! No coffee at all. Seriously? I just stood there laughing because, honestly, it's been that kind of week. Who forgets the coffee in a latte?"
        },
        {
            "type": "AI",
            "text": "Regular physical exercise is crucial for maintaining good overall health. It offers numerous benefits for both the body and the mind. Engaging in consistent physical activity helps to control body weight effectively. Furthermore, exercise can improve cardiovascular health significantly over time. Additionally, it strengthens muscles and bones, reducing the risk of injury. Regular physical exercise also boosts mental health by reducing stress and anxiety levels. Therefore, incorporating physical activity into one's daily routine is highly recommended for a healthy lifestyle."
        },
        {
            "type": "Human",
            "text": "You know that feeling when you finish a really good book and you just stare at the wall for like ten minutes? That was me last night. The ending was so unexpected, yet it made perfect sense. I was crying, smiling, just a total mess. I wish I could erase my memory and read it all over again for the first time. Truly a masterpiece."
        }
    ],
    "Traditional Chinese (ç¹ä¸­)": [
        {
            "type": "AI",
            "text": "å€å¡ŠéˆæŠ€è¡“æ˜¯ä¸€ç¨®å»ä¸­å¿ƒåŒ–çš„åˆ†æ•£å¼å¸³æœ¬æŠ€è¡“ï¼Œå®ƒç¢ºä¿äº†è³‡æ–™çš„é€æ˜æ€§èˆ‡ä¸å¯ç¯¡æ”¹æ€§ã€‚æ¯ä¸€å€‹å€å¡Šéƒ½åŒ…å«äº†å‰ä¸€å€‹å€å¡Šçš„åŠ å¯†é›œæ¹Šå€¼ã€æ™‚é–“æˆ³è¨˜ä»¥åŠäº¤æ˜“è³‡æ–™ã€‚é€™ç¨®çµæ§‹ä½¿å¾—å€å¡Šéˆåœ¨é‡‘èç§‘æŠ€ã€ä¾›æ‡‰éˆç®¡ç†ä»¥åŠæ™ºæ…§åˆç´„ç­‰é ˜åŸŸå±•ç¾å‡ºå·¨å¤§çš„æ‡‰ç”¨æ½›åŠ›ã€‚éš¨è‘—æŠ€è¡“çš„æˆç†Ÿï¼Œæˆ‘å€‘é è¨ˆå°‡çœ‹åˆ°æ›´å¤šåŸºæ–¼å€å¡Šéˆçš„å‰µæ–°è§£æ±ºæ–¹æ¡ˆã€‚"
        },
        {
            "type": "Human",
            "text": "æ˜¨å¤©è·Ÿæœ‹å‹å»æ’é‚£å®¶æ–°é–‹çš„æ‹‰éºµåº—ï¼ŒçœŸçš„æ’åˆ°å¤©è’åœ°è€ï¼æˆ‘å€‘åœ¨å¯’é¢¨ä¸­ç«™äº†å¿«å…©å€‹å°æ™‚ï¼Œè…³éƒ½å¿«æ–·äº†ã€‚çµæœé€²å»ä¸€åƒï¼Œå“‡è³½ï¼Œé‚£å€‹æ¹¯é ­æ¿ƒéƒåˆ°ä¸è¡Œï¼Œå‰ç‡’ä¹Ÿæ˜¯å…¥å£å³åŒ–ï¼Œç¬é–“è¦ºå¾—å‰›å‰›çš„è¾›è‹¦éƒ½å€¼å¾—äº†ã€‚é›–ç„¶é€™å®¶åº—çš„åƒ¹æ ¼æœ‰é»å°è²´ï¼Œä½†ä¹…ä¹…åƒä¸€æ¬¡çŠ’è³è‡ªå·±æ‡‰è©²ä¸éåˆ†å§ï¼Ÿä¸‹æ¬¡ä¸€å®šè¦æŒ‘å¹³æ—¥ä¾†ï¼Œä¸ç„¶çœŸçš„æœƒç­‰åˆ°ç˜‹æ‰ã€‚"
        },
        {
            "type": "AI",
            "text": "ç’°å¢ƒä¿è­·æ˜¯ç•¶ä»Šå…¨çƒé¢è‡¨çš„ä¸€å€‹é‡è¦è­°é¡Œã€‚éš¨è‘—å·¥æ¥­åŒ–çš„å¿«é€Ÿç™¼å±•ï¼Œè‡ªç„¶çš„ç”Ÿæ…‹å¹³è¡¡å—åˆ°äº†åš´é‡çš„æŒ‘æˆ°ã€‚æˆ‘å€‘å¿…é ˆæ„è­˜åˆ°ä¿è­·åœ°çƒå®¶åœ’çš„ç·Šè¿«æ€§èˆ‡å¿…è¦æ€§ã€‚æ¸›å°‘ä¸€æ¬¡æ€§å¡‘è† è£½å“çš„ä½¿ç”¨æ˜¯ä¸€å€‹é—œéµçš„æ­¥é©Ÿã€‚æ­¤å¤–ï¼Œç©æ¥µæ¨å»£å†ç”Ÿèƒ½æºçš„æ‡‰ç”¨ä¹Ÿæ˜¯éå¸¸é‡è¦çš„æªæ–½ã€‚æ¯å€‹äººéƒ½æ‡‰è©²æé«˜è‡ªèº«çš„ç’°ä¿æ„è­˜ä¸¦æ¡å–å¯¦éš›è¡Œå‹•ã€‚åªæœ‰é€éå…±åŒçš„åŠªåŠ›ï¼Œæˆ‘å€‘æ‰èƒ½å¯¦ç¾å¯æŒçºŒç™¼å±•çš„é•·é ç›®æ¨™ã€‚"
        },
        {
            "type": "Human",
            "text": "æ•‘å‘½å•Šï¼æˆ‘åˆšåˆšæŠŠæ‰‹æ©Ÿå¿˜åœ¨è¨ˆç¨‹è»Šä¸Šäº†ï¼Œç¾åœ¨æ•´å€‹äººè¶…ç„¦æ…®ã€‚è£¡é¢æœ‰æˆ‘æ‰€æœ‰çš„ç…§ç‰‡é‚„æœ‰æ²’å‚™ä»½çš„è¯çµ¡äººè³‡æ–™ï¼Œå¦‚æœæ‰¾ä¸å›ä¾†æˆ‘çœŸçš„æœƒå´©æ½°ã€‚å¸æ©Ÿå¤§å“¥ä¹Ÿä¸æ¥é›»è©±ï¼Œå®¢æœåˆä¸€ç›´å¿™ç·šä¸­ï¼Œé€™åˆ°åº•æ˜¯ç”šéº¼å€’æ¥£çš„ä¸€å¤©ï¼Ÿæ‹œè¨—å¥½å¿ƒäººå¦‚æœæ’¿åˆ°å¯ä»¥é€å»è­¦å¯Ÿå±€ï¼Œæˆ‘é¡˜æ„è«‹ä½ åƒå¤§é¤ç­”è¬ï¼ŒçœŸçš„æ‹œè¨—äº†ï¼"
        }
    ]
}

# --- Session State åˆå§‹åŒ– ---
if 'input_text' not in st.session_state: st.session_state['input_text'] = ""
if 'example_index' not in st.session_state: st.session_state['example_index'] = 0

# --- å´é‚Šæ¬„è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š (Settings)")
    lang_mode = st.radio("é¸æ“‡èªè¨€æ¨¡å¼", ["Traditional Chinese (ç¹ä¸­)", "English"])
    st.markdown("---")
    st.info("""
    **ğŸ§¬ Ultra æ ¸å¿ƒæŠ€è¡“ï¼š**
    é™¤äº†å¥æ³•åˆ†æå¤–ï¼Œæ­¤ç‰ˆæœ¬å¼•å…¥ **Zlib å£“ç¸®ç®—æ³•** ä¾†è¨ˆç®—ã€Œæ–‡æœ¬ç†µã€ã€‚
    - **åŸç†**ï¼šAI ç”Ÿæˆçš„æ–‡æœ¬é€šå¸¸è¦å¾‹æ€§è¼ƒå¼·ï¼Œå£“ç¸®ç‡è¼ƒé«˜ï¼ˆæª”æ¡ˆè®Šå°ï¼‰ã€‚
    - **æ¬Šé‡**ï¼šç†µå€¼ä½”è©•åˆ†çš„ 40%ã€‚
    """)

st.title(f"ğŸ§¬ {lang_mode.split('(')[0]} æ–‡æœ¬åµæ¸¬å™¨ (Ultraç‰ˆ)")

# --- åœç”¨è© ---
STOPWORDS_EN = set(['the', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'of', 'in', 'on', 'at', 'to', 'it', 'this', 'that'])
STOPWORDS_ZH = set(['çš„', 'äº†', 'å’Œ', 'æ˜¯', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'èˆ‡', 'è‘—', 'æˆ–', 'ä¸€å€‹', 'æ²’æœ‰', 'æˆ‘å€‘', 'ä½ å€‘', 'ä»–å€‘', 'åœ¨', 'é€™', 'é‚£'])

# --- æ ¸å¿ƒé‚è¼¯ï¼šåŠ å…¥ Zlib æ¼”ç®—æ³• ---
def analyze_text_features(text, mode):
    clean_text = text.strip()
    if not clean_text: return None

    # 1. åŸºç¤å‰è™•ç†
    sentences, words, stopwords = [], [], []

    if mode == "English":
        sentences = re.split(r'[.!?\n]+', clean_text)
        words = re.findall(r'\w+', clean_text.lower())
        stopwords = STOPWORDS_EN
    else:
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]+', clean_text)
        words = list(jieba.cut(clean_text))
        words = [w for w in words if w.strip() and len(w) > 0]
        stopwords = STOPWORDS_ZH

    sentences = [s.strip() for s in sentences if len(s.strip()) > 0]
    if len(words) < 5: return None

    # 2. ç‰¹å¾µ Aï¼šå¥é•·æ³¢å‹• (Burstiness)
    if mode == "English":
        sentence_lengths = [len(s.split()) for s in sentences]
    else:
        sentence_lengths = [len(list(jieba.cut(s))) for s in sentences]
    
    avg_len = np.mean(sentence_lengths)
    std_dev = np.std(sentence_lengths) if len(sentence_lengths) > 1 else 0

    # 3. ç‰¹å¾µ Bï¼šè©å½™è±å¯Œåº¦ (Type-Token Ratio)
    unique_words = set(words)
    ttr = len(unique_words) / len(words)
    filtered_words = [w for w in words if w not in stopwords and len(w) > 1]
    word_counts = Counter(filtered_words)

    # 4. ç‰¹å¾µ Cï¼šè³‡è¨Šç†µ / å£“ç¸®ç‡ (Zlib Entropy) [NEW]
    # å°‡æ–‡æœ¬è½‰ç‚º bytes ä¸¦å£“ç¸®ï¼Œè¨ˆç®—å£“ç¸®æ¯”ç‡
    text_bytes = clean_text.encode('utf-8')
    compressed_data = zlib.compress(text_bytes)
    compression_ratio = len(compressed_data) / len(text_bytes)

    # --- ç¶œåˆåŠ æ¬Šè©•åˆ†ç³»çµ± ---
    # ç›®æ¨™ï¼šå°‡å„é …æŒ‡æ¨™è½‰æ›ç‚º 0 (Human) ~ 1 (AI) çš„åˆ†æ•¸
    
    # (A) å¥é•·è©•åˆ† (30%)
    score_std = 0.5
    thresh_std_low = 5 if mode == "English" else 3
    thresh_std_high = 12 if mode == "English" else 10
    
    if std_dev < thresh_std_low: score_std = 1.0     # AI (å¹³ç©©)
    elif std_dev > thresh_std_high: score_std = 0.0  # Human (æ³¢å‹•)

    # (B) è±å¯Œåº¦è©•åˆ† (30%)
    score_ttr = 0.5
    if ttr < 0.4: score_ttr = 1.0        # AI (é‡è¤‡)
    elif ttr > 0.65: score_ttr = 0.0     # Human (è±å¯Œ)

    # (C) å£“ç¸®ç‡è©•åˆ† (40%) [æœ€é—œéµæŒ‡æ¨™]
    score_zlib = 0.5
    # æ ¹æ“šç¶“é©—æ³•å‰‡è¨­å®šçš„é–¾å€¼
    thresh_zlib_ai = 0.38 if mode == "English" else 0.43
    thresh_zlib_human = 0.50 if mode == "English" else 0.55
    
    if compression_ratio < thresh_zlib_ai: score_zlib = 1.0      # AI (è¦å¾‹å¥½å£“)
    elif compression_ratio > thresh_zlib_human: score_zlib = 0.0 # Human (æ··äº‚é›£å£“)

    # è¨ˆç®—åŠ æ¬Šå¹³å‡åˆ†
    final_score = (score_std * 0.3) + (score_ttr * 0.3) + (score_zlib * 0.4)
    
    return {
        "score": final_score, 
        "features": {
            "std_dev": std_dev,
            "ttr": ttr,
            "compression_ratio": compression_ratio
        },
        "sentences": sentences, 
        "sentence_lengths": sentence_lengths,
        "avg_len": avg_len, 
        "word_counts": word_counts,
        "total_sentences": len(sentences)
    }

# --- UI ä»‹é¢ ---
col_input, col_result = st.columns([1, 2])

with col_input:
    st.subheader("ğŸ“ è¼¸å…¥å€")
    
    # --- ğŸ² ç¯„ä¾‹æŒ‰éˆ• (ä¿æŒä½ çš„åŠŸèƒ½) ---
    def load_next_example():
        key = "English" if "English" in lang_mode else "Traditional Chinese (ç¹ä¸­)"
        examples = EXAMPLES[key]
        idx = st.session_state['example_index'] % len(examples)
        selected = examples[idx]
        st.session_state['input_text'] = selected['text']
        st.toast(f"å·²è¼‰å…¥ç¯„ä¾‹ #{idx+1} ({selected['type']})", icon="âœ…")
        st.session_state['example_index'] += 1

    st.button("ğŸ² è¼‰å…¥ç¯„ä¾‹ (è¼ªæ’­)", on_click=load_next_example, type="secondary")

    user_input = st.text_area(
        "Input Text",
        height=350, 
        placeholder="è«‹è¼¸å…¥æ–‡å­—...", 
        label_visibility="collapsed",
        key="input_text" 
    )
    
    analyze_btn = st.button("ğŸš€ é–‹å§‹æ·±åº¦åˆ†æ", type="primary")

# --- åˆ†æçµæœé¡¯ç¤º ---
if analyze_btn and user_input:
    data = analyze_text_features(user_input, lang_mode)
    
    if data is None:
        st.warning("âš ï¸ æ–‡æœ¬éçŸ­ï¼Œç„¡æ³•åˆ†æã€‚")
    else:
        with col_result:
            st.subheader("ğŸ” åˆ†æå ±å‘Š")
            
            score = data['score']
            if score > 0.65:
                res_txt, res_color = "é«˜åº¦ç–‘ä¼¼ AI ç”Ÿæˆ", "red"
            elif score < 0.35:
                res_txt, res_color = "å¯èƒ½æ˜¯ Human æ’°å¯«", "green"
            else:
                res_txt, res_color = "æ··åˆç‰¹å¾µ / ä¸ç¢ºå®š", "orange"

            st.markdown(f"""
            <div style="padding:15px; border-radius:10px; background-color:rgba(128,128,128,0.1); border-left: 6px solid {res_color}">
                <h3 style="margin:0; color:{res_color}">{res_txt}</h3>
                <p style="margin:5px 0 0 0; opacity:0.8">AI å¯èƒ½æ€§æŒ‡æ•¸: <b>{int(score*100)}%</b></p>
            </div>
            """, unsafe_allow_html=True)
            
            st.write("")

            # --- 3å€‹é—œéµæŒ‡æ¨™ Dashboard (æ–°å¢å£“ç¸®ç‡) ---
            f = data['features']
            c1, c2, c3 = st.columns(3)
            
            c1.metric("1. å¥é•·æ³¢å‹•åº¦", f"{f['std_dev']:.1f}", 
                      delta="ä½ (åƒAI)" if f['std_dev'] < 5 else "é«˜ (åƒäºº)", delta_color="inverse")
            
            c2.metric("2. è©å½™è±å¯Œåº¦", f"{f['ttr']:.2f}",
                      delta="ä½ (åƒAI)" if f['ttr'] < 0.4 else "é«˜ (åƒäºº)", delta_color="inverse")
            
            c3.metric("3. è³‡è¨Šç†µ (å£“ç¸®ç‡)", f"{f['compression_ratio']:.2f}",
                      delta="ä½ (åƒAI)" if f['compression_ratio'] < 0.4 else "é«˜ (åƒäºº)", delta_color="inverse",
                      help="æ•¸å€¼è¶Šä½ä»£è¡¨æ–‡æœ¬è¶Šè¦å¾‹ã€è¶Šå®¹æ˜“è¢«é æ¸¬ (AIç‰¹å¾µ)")

            # --- åœ–è¡¨å€ ---
            tab1, tab2 = st.tabs(["ğŸ“ˆ å¥å‹çµæ§‹åˆ†æ", "ğŸ”  å¸¸ç”¨è©å½™çµ±è¨ˆ"])

            with tab1:
                st.caption("Human é€šå¸¸å¥é•·æ³¢å‹•å¤§ (ç·šæ¢åŠ‡çƒˆè·³å‹•)ï¼›AI å‰‡è¼ƒå¹³ç©©ã€‚")
                chart_data = pd.DataFrame({
                    "å¥åº": range(1, len(data['sentence_lengths']) + 1),
                    "è©æ•¸": data['sentence_lengths']
                })
                st.line_chart(chart_data, x="å¥åº", y="è©æ•¸", color="#FF4B4B")

            with tab2:
                top_words = data['word_counts'].most_common(10)
                if top_words:
                    words_df = pd.DataFrame(top_words, columns=["è©å½™", "æ¬¡æ•¸"])
                    st.bar_chart(words_df.set_index("è©å½™"))
                else:
                    st.info("é—œéµå­—æ•¸æ“šä¸è¶³")

elif not analyze_btn:
    with col_result:
        st.info("ğŸ‘ˆ é»æ“Šã€ŒğŸ² è¼‰å…¥ç¯„ä¾‹ã€æ¸¬è©¦æœ€æ–°çš„å¤šç¶­åº¦åµæ¸¬æ¼”ç®—æ³•ã€‚")